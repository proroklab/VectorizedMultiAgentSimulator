{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "VMAS: Use vmas environment.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "0NsC_EwfCF5I"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Initialization"
   ],
   "metadata": {
    "id": "0NsC_EwfCF5I"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cP9ijqwvIXGd",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "! git clone https://github.com/proroklab/VectorizedMultiAgentSimulator.git"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "%cd /content/VectorizedMultiAgentSimulator\n",
    "\n",
    "!pip install -r requirements.txt\n",
    "!apt-get update\n",
    "!apt-get install -y x11-utils \n",
    "!apt-get install -y xvfb\n",
    "!apt-get install -y imagemagick\n",
    "!pip install -e ."
   ],
   "metadata": {
    "id": "zjnXLxaOMLuv",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "!pip install pyvirtualdisplay\n",
    "import pyvirtualdisplay\n",
    "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
    "display.start()"
   ],
   "metadata": {
    "id": "5wilTW60cNr4",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run\n"
   ],
   "metadata": {
    "id": "jAAA3DXGCLkF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#  Copyright (c) 2022.\n",
    "#  ProrokLab (https://www.proroklab.org/)\n",
    "#  All rights reserved.\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from vmas import make_env, Wrapper\n",
    "\n",
    "scenario_name = \"waterfall\"\n",
    "\n",
    "# Scenario specific variables\n",
    "n_agents = 4\n",
    "\n",
    "num_envs = 32\n",
    "continuous_actions = False\n",
    "device = \"cpu\"  # or cuda or any other torch device\n",
    "wrapper = None # or None\n",
    "n_steps = 200\n",
    "\n",
    "simple_2d_action = (\n",
    "    [0, 0.5] if continuous_actions else [3]\n",
    ")  # Sample action tell each agent to go down\n",
    "\n",
    "env = make_env(\n",
    "    scenario_name=scenario_name,\n",
    "    num_envs=num_envs,\n",
    "    device=device,\n",
    "    continuous_actions=continuous_actions,\n",
    "    wrapper=wrapper,\n",
    "    # Environment specific variables\n",
    "    n_agents=n_agents,\n",
    ")\n",
    "\n",
    "\n",
    "frame_list = []  # For creating a gif\n",
    "init_time = time.time()\n",
    "for s in range(n_steps):\n",
    "    actions = []\n",
    "    if wrapper is Wrapper.RLLIB:  # Rllib interface\n",
    "        for i in range(num_envs):\n",
    "            actions_per_env = []\n",
    "            for j in range(n_agents):\n",
    "                actions_per_env.append(np.array(simple_2d_action))\n",
    "            actions.append(actions_per_env)\n",
    "        obs, rews, dones, info = env.vector_step(actions)\n",
    "        frame_list.append(\n",
    "            Image.fromarray(\n",
    "                env.try_render_at(\n",
    "                    mode=\"rgb_array\", agent_index_focus=None # Can give the camera an agent index to focus on\n",
    "                )\n",
    "            )\n",
    "        )  \n",
    "\n",
    "    elif wrapper is None:  # Same as before, with faster VMAS interface\n",
    "        for i in range(n_agents):\n",
    "            actions.append(\n",
    "                torch.tensor(\n",
    "                    simple_2d_action,\n",
    "                    device=device,\n",
    "                ).repeat(num_envs, 1)\n",
    "            )\n",
    "        obs, rews, dones, info = env.step(actions)\n",
    "        frame_list.append(\n",
    "            Image.fromarray(env.render(mode=\"rgb_array\", agent_index_focus=None))\n",
    "        )  # Can give the camera an agent index to focus on\n",
    "\n",
    "gif_name = scenario_name + \".gif\"\n",
    "\n",
    "# Produce a gif\n",
    "frame_list[0].save(\n",
    "    gif_name,\n",
    "    save_all=True,\n",
    "    append_images=frame_list[1:],\n",
    "    duration=3,\n",
    "    loop=0,\n",
    ")\n",
    "\n",
    "total_time = time.time() - init_time\n",
    "print(\n",
    "        f\"It took: {total_time}s for {n_steps} steps of {num_envs} parallel environments on device {device}\"\n",
    "        f\" for {wrapper.name + ' wrapped ' if wrapper is not None else ''}simulator\"\n",
    "    )"
   ],
   "metadata": {
    "id": "2Ol4AFeRQ3Ma"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "Image(open(f'{scenario_name}.gif','rb').read())"
   ],
   "metadata": {
    "id": "UPRa91hMPU1n"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "# Requires imagemagick to be installed to convert the gif in faster format\n",
    "os.system(f\"convert -delay 1x30 -loop 0 {gif_name} {scenario_name}_fast.gif\")\n",
    "from IPython.display import Image\n",
    "Image(open(f'{scenario_name}_fast.gif','rb').read())"
   ],
   "metadata": {
    "id": "BohliLebMOJB"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
